{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Armik\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xAhRcgdAVJzn"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rqml_x5JVJ0H"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_func import morpher, sw, exclude, preprocess_txt, embed_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936be216300b4ada95f45b9554faf125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anecd_data = []\n",
    "anecd_origin = []\n",
    "\n",
    "c = 0\n",
    "\n",
    "with open(\"../data/anek_djvu.txt\", \"r\", encoding='utf-8') as fin:\n",
    "    for line in tqdm(fin):\n",
    "        if line.startswith(\"<|startoftext|>\"):\n",
    "            line = line.replace('<|startoftext|>', '')\n",
    "            anecd_origin.append(line)\n",
    "            spls = preprocess_txt(line)\n",
    "            anecd_data.append(spls)\n",
    "            \n",
    "            if c > 10000:\n",
    "                break\n",
    "            c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['посещать',\n",
       " 'мысль',\n",
       " 'смерть',\n",
       " 'полбеды',\n",
       " 'беда',\n",
       " 'смерть',\n",
       " 'посещать',\n",
       " 'мысль']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(anecd_data))\n",
    "anecd_data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT = FastText.load(\"../data/bot_trained/ft_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/bot_trained/index_speaker.pkl\",\"rb\") as f:\n",
    "    bin_data = f.read()\n",
    "    index_loaded = pickle.loads(bin_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Xfxh1xO9VJ0I"
   },
   "outputs": [],
   "source": [
    "idxs = set(np.random.randint(0, len(index_loaded), len(anecd_data)))\n",
    "negative_speaker_texts = [\" \".join(preprocess_txt(index_loaded[i])) for i in idxs]\n",
    "positive_texts = [\" \".join(val) for val in anecd_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9034"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_speaker_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3ud68payVJ0J"
   },
   "outputs": [],
   "source": [
    "dataset = negative_speaker_texts + positive_texts\n",
    "labels = np.zeros(len(dataset))\n",
    "labels[len(negative_speaker_texts):] = np.ones(len(positive_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19036\n",
      "19036\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "N_oxnOuzVJ0K"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.2, stratify=labels,\n",
    "                                                    random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "tNzqfsIZVJ0K",
    "outputId": "d3173275-3a00-47e2-8243-372f61a627c5"
   },
   "outputs": [],
   "source": [
    "x_train_vec = vectorizer.fit_transform(X_train)\n",
    "x_test_vec = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15228"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3808, 319819)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_anecd = LogisticRegression(max_iter=1000).fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "q_bWwksAVJ0L",
    "outputId": "e410d691-e516-45aa-ac0e-d8ef0378cc4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7765231092436975"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=lr_anecd.predict(x_test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(lr_anecd, open('../data/bot_trained/lr_model_anecd.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "XFgbubh7VJ0N"
   },
   "outputs": [],
   "source": [
    "# vectorizing for annoy\n",
    "tfidf_vect_anecd = TfidfVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bot_trained/lr_vect_tfidf_anecd.pkl', 'wb') as fout:\n",
    "    pickle.dump((vectorizer, tfidf_vect_anecd, lr_anecd), fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "yx8AkUiiVJ0N",
    "outputId": "dce321cc-2846-4c1c-a42e-c6aff189837e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.589800403314408"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tfidf_vect_anecd.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idfs_anecd, midf_anecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "aQQG_bluVJ0O",
    "outputId": "90701b9a-a491-417a-a291-fc3209df90fb"
   },
   "outputs": [],
   "source": [
    "idfs_anecd = {v[0]: v[1] for v in zip(tfidf_vect_anecd.vocabulary_, tfidf_vect_anecd.idf_)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['протестировать', 'микро', 'работать', 'вообще', 'любой', 'желание', 'причина', 'создавать', 'цепь', 'событие']\n",
      "[9.2446624227318, 7.0756087223622774, 9.937809603291745, 9.937809603291745, 9.937809603291745, 9.937809603291745, 9.937809603291745, 9.937809603291745, 9.937809603291745, 9.937809603291745]\n"
     ]
    }
   ],
   "source": [
    "print(list(idfs_anecd.keys())[:10])\n",
    "print(list(idfs_anecd.values())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "9ae8735faac34a36be98a6d1f1fcd62e"
     ]
    },
    "id": "JjWyFjJBVJ0P",
    "outputId": "69c1e269-b020-4542-9b84-812cc5485b08"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc28b335eb14c9aaa7fdec9943fe44c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating indexes for anecdote texts\n",
    "\n",
    "ft_index_anecd = annoy.AnnoyIndex(100 ,'angular')\n",
    "\n",
    "midf_anecd = np.mean(tfidf_vect_anecd.idf_)\n",
    "\n",
    "index_map_anecd = {}\n",
    "counter = 0\n",
    "\n",
    "for i in tqdm(range(len(anecd_data))):\n",
    "    n_ft = 0\n",
    "    index_map_anecd[counter] = (anecd_origin[i])\n",
    "    vector_ft = np.zeros(100)\n",
    "    for word in anecd_data[i]:\n",
    "        if word in modelFT.wv:\n",
    "            vector_ft += modelFT.wv[word] * idfs_anecd.get(word, midf_anecd)\n",
    "            n_ft += idfs_anecd.get(word, midf_anecd)\n",
    "    if n_ft > 0:\n",
    "        vector_ft = vector_ft / n_ft\n",
    "    ft_index_anecd.add_item(counter, vector_ft)\n",
    "    counter += 1\n",
    "\n",
    "ft_index_anecd.build(10)\n",
    "ft_index_anecd.save('../data/bot_trained/anecd.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Iwnz2qFTVJ0Q"
   },
   "outputs": [],
   "source": [
    "with open(\"../data/bot_trained/index_anecd.pkl\", \"wb\") as f:\n",
    "    pickle.dump(index_map_anecd, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "H3jf5wMsVJ0R",
    "outputId": "d6f9717b-3d10-472e-bc27-893bf19f21bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([76], [1.4142135381698608])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_index_anecd.get_nns_by_vector(np.zeros(100), 1, include_distances=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/bot_trained/midf_anecd', midf_anecd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "lesson_16.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
